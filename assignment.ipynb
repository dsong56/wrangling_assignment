{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
   "metadata": {
    "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
   },
   "source": [
    "# Assignment: Data Wrangling\n",
    "### `! git clone https://github.com/ds3001f25/wrangling_assignment.git`\n",
    "### Do Q1 and Q2\n",
    "### Reading material: `tidy_data.pdf`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
   "metadata": {
    "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
   },
   "source": [
    "**Q1.** This question provides some practice cleaning variables which have common problems.\n",
    "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
    "2. Categorical variable: For the Minnesota police use of for data, `./data/mn_police_use_of_force.csv`, clean the `subject_injury` variable, handling the NA's; this gives a value `Yes` when a person was injured by police, and `No` when no injury occurred. What proportion of the values are missing? Is this a concern? Cross-tabulate your cleaned `subject_injury` variable with the `force_type` variable. Are there any patterns regarding when the data are missing? \n",
    "3. Dummy variable: For the pretrial data covered in the lecture `./data/justice_data.parquet`, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
    "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d412a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\dsong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\dsong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dsong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dsong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dsong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dsong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\dsong\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in c:\\users\\dsong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\dsong\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xlrd in c:\\users\\dsong\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\dsong\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not find a version that satisfies the requirement re (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\dsong\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for re\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "    Host Id Host Since                                Name Neighbourhood   \\\n",
      "0   5162530        NaN     1 Bedroom in Prime Williamsburg       Brooklyn   \n",
      "1  33134899        NaN     Sunny, Private room in Bushwick       Brooklyn   \n",
      "2  39608626        NaN                Sunny Room in Harlem      Manhattan   \n",
      "3       500  6/26/2008  Gorgeous 1 BR with Private Balcony      Manhattan   \n",
      "4       500  6/26/2008            Trendy Times Square Loft      Manhattan   \n",
      "\n",
      "  Property Type  Review Scores Rating (bin)        Room Type  Zipcode  Beds  \\\n",
      "0     Apartment                         NaN  Entire home/apt  11249.0   1.0   \n",
      "1     Apartment                         NaN     Private room  11206.0   1.0   \n",
      "2     Apartment                         NaN     Private room  10032.0   1.0   \n",
      "3     Apartment                         NaN  Entire home/apt  10024.0   3.0   \n",
      "4     Apartment                        95.0     Private room  10036.0   3.0   \n",
      "\n",
      "   Number of Records  Number Of Reviews  Price  Review Scores Rating  Price_NA  \n",
      "0                  1                  0  145.0                   NaN     False  \n",
      "1                  1                  1   37.0                   NaN     False  \n",
      "2                  1                  1   28.0                   NaN     False  \n",
      "3                  1                  0  199.0                   NaN     False  \n",
      "4                  1                 39  549.0                  96.0     False  \n",
      "Total missing values: 181\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install xlrd\n",
    "%pip install re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Q1.1\n",
    "df_price = pd.read_csv(\"./data/airbnb_hw.csv\", low_memory=False)\n",
    "\n",
    "df_price['Price'] = df_price['Price'].astype(str) # str type to be able to remove commas\n",
    "df_price['Price'] = df_price['Price'].str.strip().replace(',','') # removing commas\n",
    "df_price['Price'] = pd.to_numeric(df_price['Price'], errors='coerce') # converting type into float\n",
    "\n",
    "\n",
    "df_price['Price_NA'] = df_price['Price'].isnull() # check for null values\n",
    "print(df_price.head())\n",
    "print('Total missing values:', sum(df_price['Price_NA']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a33c5b9",
   "metadata": {},
   "source": [
    "2. Categorical variable: For the Minnesota police use of for data, `./data/mn_police_use_of_force.csv`, clean the `subject_injury` variable, handling the NA's; this gives a value `Yes` when a person was injured by police, and `No` when no injury occurred. What proportion of the values are missing? Is this a concern? Cross-tabulate your cleaned `subject_injury` variable with the `force_type` variable. Are there any patterns regarding when the data are missing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99b04f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion missing: 76.19342359767892 %\n",
      "Cleaned subject_injury: [nan 'No' 'Yes']\n",
      "Cross-tabulation:\n",
      " force_type      Baton  Bodily Force  Chemical Irritant  Firearm  \\\n",
      "subject_injury                                                    \n",
      "Missing             2          7051               1421        0   \n",
      "No                  0          1093                131        2   \n",
      "Yes                 2          1286                 41        0   \n",
      "\n",
      "force_type      Gun Point Display  Improvised Weapon  Less Lethal  \\\n",
      "subject_injury                                                      \n",
      "Missing                        27                 74           87   \n",
      "No                             33                 34            0   \n",
      "Yes                            44                 40            0   \n",
      "\n",
      "force_type      Less Lethal Projectile  Maximal Restraint Technique  \\\n",
      "subject_injury                                                        \n",
      "Missing                              0                          170   \n",
      "No                                   1                            0   \n",
      "Yes                                  2                            0   \n",
      "\n",
      "force_type      Police K9 Bite  Taser  \n",
      "subject_injury                         \n",
      "Missing                     31    985  \n",
      "No                           2    150  \n",
      "Yes                         44    172  \n"
     ]
    }
   ],
   "source": [
    "#Q1.2\n",
    "df_injury = pd.read_csv(\"./data/mn_police_use_of_force.csv\", low_memory=False)\n",
    "\n",
    "missing = df_injury['subject_injury'].isnull()\n",
    "print('Proportion missing:', missing.mean()*100, \"%\")\n",
    "print(\"Cleaned subject_injury:\", df_injury['subject_injury'].unique())\n",
    "df_injury['subject_injury'] = df_injury['subject_injury'].replace(np.nan, 'Missing')\n",
    "df_injury['subject_injury'] = df_injury['subject_injury'].str.strip()\n",
    "\n",
    "ctab = pd.crosstab(df_injury['subject_injury'], df_injury['force_type'])\n",
    "print(\"Cross-tabulation:\\n\", ctab.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d4635",
   "metadata": {},
   "source": [
    "About 76% of the 'subject_injury' values are missing, which is quite high and definitely a concern.\n",
    "The cross tabulation shows that the majority of missing values for 'subject_injury' come from common force types such as Bodily Force and Chemical Irritant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18fa1c",
   "metadata": {},
   "source": [
    "3. Dummy variable: For the pretrial data covered in the lecture ./data/justice_data.parquet, clean the WhetherDefendantWasReleasedPretrial variable as well as you can, and, in particular, replace missing values with np.nan. 4. Missing values, not at random: For the pretrial data covered in the lecture, clean the ImposedSentenceAllChargeInContactEvent variable as well as you can, and explain the choices you make. (Hint: Look at the SentenceTypeAllChargesAtConvictionInContactEvent variable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb890ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: [9 0 1]\n",
      "After cleaning: [nan  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "#Q1.3\n",
    "df_justice = pd.read_parquet(\"./data/justice_data.parquet\", engine=\"pyarrow\")\n",
    "print(\"Before cleaning:\", df_justice[\"WhetherDefendantWasReleasedPretrial\"].unique())\n",
    "df_justice['WhetherDefendantWasReleasedPretrial'] = df_justice['WhetherDefendantWasReleasedPretrial'].replace(9,np.nan)\n",
    "print(\"After cleaning:\", df_justice[\"WhetherDefendantWasReleasedPretrial\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28dc44",
   "metadata": {},
   "source": [
    "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ff7d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: 0                    \n",
      "1                  60\n",
      "2                  12\n",
      "3    .985626283367556\n",
      "4                    \n",
      "Name: ImposedSentenceAllChargeInContactEvent, dtype: object\n",
      "After cleaning: 0          NaN\n",
      "1          NaN\n",
      "2    12.000000\n",
      "3     0.985626\n",
      "4          NaN\n",
      "Name: ImposedSentenceAllChargeInContactEvent, dtype: float64\n",
      "Missing values: 17773\n",
      "Total rows: 22986\n",
      "Unique sentence types:\n",
      "[0. 1. 4. 2.]\n"
     ]
    }
   ],
   "source": [
    "#Q1.4\n",
    "\n",
    "print(\"Before cleaning:\", df_justice['ImposedSentenceAllChargeInContactEvent'].head())\n",
    "df_justice['ImposedSentenceAllChargeInContactEvent'] = df_justice['ImposedSentenceAllChargeInContactEvent'].replace(' ', np.nan) # replacing with np.nan\n",
    "\n",
    "# Step 2: Convert to numeric (some were strings like '12.98...')\n",
    "df_justice['ImposedSentenceAllChargeInContactEvent'] = pd.to_numeric(df_justice['ImposedSentenceAllChargeInContactEvent'], errors='coerce' # convert\n",
    ")\n",
    "\n",
    "# Step 3: Replace Sentence Type code 9 (\"unknown\") with NaN\n",
    "df_justice['SentenceTypeAllChargesAtConvictionInContactEvent'] = df_justice['SentenceTypeAllChargesAtConvictionInContactEvent'].replace(9, np.nan) # replace 9 with NaN\n",
    "\n",
    "# Step 4: If SentenceType == 0 (likely \"no sentence\"), then set sentence value to NaN\n",
    "df_justice.loc[df_justice['SentenceTypeAllChargesAtConvictionInContactEvent'] == 0,\n",
    "    'ImposedSentenceAllChargeInContactEvent'] = np.nan\n",
    "\n",
    "print(\"After cleaning:\", df_justice['ImposedSentenceAllChargeInContactEvent'].head())\n",
    "\n",
    "print(\"Missing values:\", df_justice['ImposedSentenceAllChargeInContactEvent'].isna().sum())\n",
    "print(\"Total rows:\", len(df_justice))\n",
    "\n",
    "print(\"Unique sentence types:\")\n",
    "print(df_justice['SentenceTypeAllChargesAtConvictionInContactEvent'].dropna().unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60a44e",
   "metadata": {},
   "source": [
    "**Q2.** Go to https://sharkattackfile.net/ and download their dataset on shark attacks (Hint: `GSAF5.xls`).\n",
    "\n",
    "1. Open the shark attack file using Pandas. It is probably not a csv file, so `read_csv` won't work.\n",
    "2. Drop any columns that do not contain data.\n",
    "3. Clean the year variable. Describe the range of values you see. Filter the rows to focus on attacks since 1940. Are attacks increasing, decreasing, or remaining constant over time?\n",
    "4. Clean the Age variable and make a histogram of the ages of the victims.\n",
    "5. What proportion of victims are male?\n",
    "6. Clean the `Type` variable so it only takes three values: Provoked and Unprovoked and Unknown. What proportion of attacks are unprovoked?\n",
    "7. Clean the `Fatal Y/N` variable so it only takes three values: Y, N, and Unknown.\n",
    "8. Are sharks more likely to launch unprovoked attacks on men or women? Is the attack more or less likely to be fatal when the attack is provoked or unprovoked? Is it more or less likely to be fatal when the victim is male or female? How do you feel about sharks?\n",
    "9. What proportion of attacks appear to be by white sharks? (Hint: `str.split()` makes a vector of text values into a list of lists, split by spaces.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3f03830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 21</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16th August 2025</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>Cayo Costa Boca Grande</td>\n",
       "      <td>Fishing</td>\n",
       "      <td>Shawn Meuse</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>Lemon shark 1.8 m (6ft)</td>\n",
       "      <td>Johannes Marchand: Kevin McMurray Trackingshar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Cabarita Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Brad Ross</td>\n",
       "      <td>M</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>5m (16.5ft) Great White</td>\n",
       "      <td>Bob Myatt GSAF The Guardian: 9 News: ABS News:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Bahamas</td>\n",
       "      <td>Atlantic Ocean near Big Grand Cay</td>\n",
       "      <td>North of Grand Bahama near Freeport</td>\n",
       "      <td>Spearfishing</td>\n",
       "      <td>Not stated</td>\n",
       "      <td>M</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Ralph Collier GSAF and Kevin MCMurray Tracking...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7th August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Australia</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Tathra Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Bowie Daley</td>\n",
       "      <td>M</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>Suspected Great White</td>\n",
       "      <td>Bob Myatt GSAF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st August</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>Carolina Beach</td>\n",
       "      <td>Wading</td>\n",
       "      <td>Eleonora Boi</td>\n",
       "      <td>F</td>\n",
       "      <td>39</td>\n",
       "      <td>...</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Kevin McMurray Trackingsharks.com: NY Post</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date    Year        Type      Country  \\\n",
       "0  16th August 2025  2025.0    Provoked          USA   \n",
       "1       18th August  2025.0  Unprovoked    Australia   \n",
       "2       17th August  2025.0  Unprovoked      Bahamas   \n",
       "3        7th August  2025.0  Unprovoked    Australia   \n",
       "4        1st August  2025.0  Unprovoked  Puerto Rico   \n",
       "\n",
       "                               State                             Location  \\\n",
       "0                            Florida               Cayo Costa Boca Grande   \n",
       "1                                NSW                       Cabarita Beach   \n",
       "2  Atlantic Ocean near Big Grand Cay  North of Grand Bahama near Freeport   \n",
       "3                                NSW                        Tathra Beach    \n",
       "4                           Carolina                       Carolina Beach   \n",
       "\n",
       "       Activity          Name Sex Age  ...                 Species   \\\n",
       "0       Fishing   Shawn Meuse   M   ?  ...  Lemon shark 1.8 m (6ft)   \n",
       "1       Surfing     Brad Ross   M   ?  ...  5m (16.5ft) Great White   \n",
       "2  Spearfishing    Not stated   M  63  ...             Undetermined   \n",
       "3       Surfing   Bowie Daley   M   9  ...    Suspected Great White   \n",
       "4        Wading  Eleonora Boi   F  39  ...             Undetermined   \n",
       "\n",
       "                                              Source  pdf href formula href  \\\n",
       "0  Johannes Marchand: Kevin McMurray Trackingshar...  NaN          NaN  NaN   \n",
       "1  Bob Myatt GSAF The Guardian: 9 News: ABS News:...  NaN          NaN  NaN   \n",
       "2  Ralph Collier GSAF and Kevin MCMurray Tracking...  NaN          NaN  NaN   \n",
       "3                                     Bob Myatt GSAF  NaN          NaN  NaN   \n",
       "4         Kevin McMurray Trackingsharks.com: NY Post  NaN          NaN  NaN   \n",
       "\n",
       "  Case Number Case Number.1 original order Unnamed: 21 Unnamed: 22  \n",
       "0         NaN           NaN            NaN         NaN         NaN  \n",
       "1         NaN           NaN            NaN         NaN         NaN  \n",
       "2         NaN           NaN            NaN         NaN         NaN  \n",
       "3         NaN           NaN            NaN         NaN         NaN  \n",
       "4         NaN           NaN            NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Q2.1\n",
    "df = pd.read_excel(\"GSAF5.xls\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e42d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['Date', 'Year', 'Type', 'Country', 'State', 'Location', 'Activity', 'Name', 'Sex', 'Age', 'Injury', 'Fatal Y/N', 'Time', 'Species ', 'Source', 'pdf', 'href formula', 'href', 'Case Number', 'Case Number.1', 'original order', 'Unnamed: 21', 'Unnamed: 22']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Q2.2\n",
    "df = df.dropna(axis=1, how='all')  # drop empty columns\n",
    "print(\"Columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fde20cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year range: 1940.0 , 2025.0\n",
      "First few year counts:\n",
      " Year\n",
      "1940.0    24\n",
      "1941.0    27\n",
      "1942.0    41\n",
      "1943.0    28\n",
      "1944.0    31\n",
      "Name: count, dtype: int64\n",
      "Last few year counts:\n",
      " Year\n",
      "2021.0    110\n",
      "2022.0     98\n",
      "2023.0    109\n",
      "2024.0     52\n",
      "2025.0     48\n",
      "Name: count, dtype: int64\n",
      "Overall trend in shark attacks over time: increasing overall\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Q2.3\n",
    "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')  # numeric\n",
    "df = df[df['Year'].between(1940, 2025)]  # year change\n",
    "print(\"Year range:\", df['Year'].min(), \",\", df['Year'].max())\n",
    "\n",
    "attacks_per_year = df[\"Year\"].value_counts().sort_index() # look at trend over time\n",
    "print(\"First few year counts:\\n\", attacks_per_year.head())\n",
    "print(\"Last few year counts:\\n\", attacks_per_year.tail())\n",
    "\n",
    "early_mean = attacks_per_year.loc[1900:1950].mean() # filtering based on past attacks\n",
    "recent_mean = attacks_per_year.loc[2000:].mean() # filtering based on recent attacks\n",
    "if recent_mean > early_mean * 1.25: # recent rate must be at least 25% higher to be increasing\n",
    "    trend = \"increasing overall\"\n",
    "elif recent_mean < early_mean * 0.75: # recent rate must be at least 25% lower to be decreasing\n",
    "    trend = \"decreasing overall\"\n",
    "else:\n",
    "    trend = \"roughly constant\"\n",
    "print(\"Overall trend in shark attacks over time:\", trend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dde96afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age summary: count    3599.000000\n",
      "mean       28.600445\n",
      "std        14.796239\n",
      "min         1.000000\n",
      "25%        17.000000\n",
      "50%        25.000000\n",
      "75%        37.000000\n",
      "max        87.000000\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Q2.4\n",
    "df['Age'] = pd.to_numeric(df['Age'], errors='coerce')  # convert\n",
    "print(\"Age summary:\", df['Age'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1ef82e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions: Sex\n",
      "M        0.786052\n",
      "F        0.130222\n",
      "NaN      0.082092\n",
      "M        0.000545\n",
      "F        0.000363\n",
      " M       0.000182\n",
      "m        0.000182\n",
      "lli      0.000182\n",
      "M x 2    0.000182\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Q2.5\n",
    "sex_counts = df['Sex'].value_counts(dropna=False) # finding number of entries\n",
    "sex_proportions = sex_counts / sex_counts.sum() # finding proportion\n",
    "print(\"Proportions:\", sex_proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c570d590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack types: Type\n",
      "unprovoked    4097\n",
      "unknown        891\n",
      "provoked       518\n",
      "Name: count, dtype: int64\n",
      "Unprovoked proportion: 0.7440973483472575\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Q2.6\n",
    "df['Type'] = df['Type'].astype(str)\n",
    "df['Type'] = df['Type'].str.lower()\n",
    "df['Type'] = df['Type'].where(df['Type'].isin(['provoked', 'unprovoked']), 'unknown') # using provoked and unprovoked, everything else goes into unknown\n",
    "\n",
    "type_counts = df['Type'].value_counts(dropna=False)\n",
    "print(\"Attack types:\", type_counts)\n",
    "print(\"Unprovoked proportion:\", type_counts['unprovoked'] / type_counts.sum())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1e40bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts: Fatal Y/N\n",
      "N          4218\n",
      "Y           825\n",
      "Unknown     463\n",
      "Name: count, dtype: int64\n",
      "Unique values: ['N' 'Y' 'Unknown']\n"
     ]
    }
   ],
   "source": [
    "# Q2.7\n",
    "df['Fatal Y/N'] = df['Fatal Y/N'].astype(str)\n",
    "df['Fatal Y/N'] = df['Fatal Y/N'].str.lower()\n",
    "df['Fatal Y/N'] = df['Fatal Y/N'].replace({\n",
    "    \"y\": \"Y\",\n",
    "    \"yes\": \"Y\",\n",
    "    \"y x 2\": \"Y\",\n",
    "    \"n\": \"N\",\n",
    "    \"no\": \"N\",\n",
    "    \"f\": \"N\",\n",
    "})\n",
    "df['Fatal Y/N'] = np.where(df['Fatal Y/N'].isin([\"Y\",\"N\"]), df['Fatal Y/N'], \"Unknown\")\n",
    "\n",
    "print(\"Value Counts:\", df['Fatal Y/N'].value_counts())\n",
    "print(\"Unique values:\", df['Fatal Y/N'].unique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "703ce8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacks by Sex and Type:\n",
      " Type   provoked   unknown  unprovoked\n",
      "Sex                                  \n",
      " M     0.000000  0.000000    1.000000\n",
      "F      0.039052  0.110181    0.850767\n",
      "F      0.000000  0.000000    1.000000\n",
      "M      0.103050  0.125693    0.771257\n",
      "M      0.000000  0.000000    1.000000\n",
      "M x 2  0.000000  1.000000    0.000000\n",
      "lli    0.000000  0.000000    1.000000\n",
      "m      0.000000  0.000000    1.000000\n",
      "Fatality by Type:\n",
      " Fatal Y/N          N   Unknown         Y\n",
      "Type                                    \n",
      "provoked    0.955598  0.021236  0.023166\n",
      "unknown     0.414141  0.445567  0.140292\n",
      "unprovoked  0.818648  0.013424  0.167928\n",
      "\n",
      "Fatality by Sex:\n",
      " Fatal Y/N         N   Unknown         Y\n",
      "Sex                                    \n",
      " M         1.000000  0.000000  0.000000\n",
      "F          0.792190  0.083682  0.124128\n",
      "F          1.000000  0.000000  0.000000\n",
      "M          0.773105  0.074861  0.152033\n",
      "M          0.666667  0.000000  0.333333\n",
      "M x 2      0.000000  0.000000  1.000000\n",
      "lli        1.000000  0.000000  0.000000\n",
      "m          1.000000  0.000000  0.000000\n"
     ]
    }
   ],
   "source": [
    "# Q2.8\n",
    "print(\"Attacks by Sex and Type:\\n\", \n",
    "      pd.crosstab(df['Sex'], df['Type'], normalize='index').to_string())\n",
    "print(\"Fatality by Type:\\n\", \n",
    "      pd.crosstab(df['Type'], df['Fatal Y/N'], normalize='index').to_string())\n",
    "\n",
    "print(\"\\nFatality by Sex:\\n\", \n",
    "      pd.crosstab(df['Sex'], df['Fatal Y/N'], normalize='index').to_string())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8421d29f",
   "metadata": {},
   "source": [
    "- The table shows that about 85% of attacks on women are unprovoked, whereas about 77% of attacks on men are unprovoked. Therefore, unprovoked attacks are more likely to happen to women than men.\n",
    "\n",
    "- The table shows that provoked attacks are only fatal about 2.3% of the time and unprovoked attacks are fatal about 16.8% of the time. Therefore, unprovoked attacks are more likely to be fatal than provoked attacks.\n",
    "\n",
    "- The table shows that of female victims, 12.4% of the attacks are fatal, whereas for male victims, 15.2% of attacks are fatal. Therefore, attacks on men are more likely to be fatal than those on women. \n",
    "\n",
    "- Although shark attacks are rare, the data shows that they are usually unprovoked and more dangerous when they are. Men are more frequently attacked, but women’s attacks are even more likely to be unprovoked. The results suggest that sharks are not malicious, but act based on their instincts. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38a3bc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with white: 668 out of 5506 total\n",
      "Proportion of attacks from white sharks:  0.1213221939702143\n"
     ]
    }
   ],
   "source": [
    "# Q2.9\n",
    "df['Species '] = df['Species '].astype(str)\n",
    "df['Species '] = df['Species '].str.lower().str.strip() # clean\n",
    "\n",
    "species_split = df['Species '].str.split() # split by spaces into lists\n",
    "\n",
    "is_white = species_split.apply(lambda x: ('white' in x)) # find rows with white\n",
    "\n",
    "count_white = is_white.sum()\n",
    "total = df['Species '].notna().sum()\n",
    "print(\"Rows with white:\", count_white, \"out of\", len(df), \"total\")\n",
    "print(\"Proportion of attacks from white sharks: \", count_white/len(df))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
